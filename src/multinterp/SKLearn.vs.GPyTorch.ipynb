{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 20\n",
    "train_x = torch.zeros(pow(n, 2), 2)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        # Each coordinate varies from 0 to 1 in n=100 steps\n",
    "        train_x[i * n + j][0] = float(i) / (n - 1)\n",
    "        train_x[i * n + j][1] = float(j) / (n - 1)\n",
    "\n",
    "train_y_1 = (\n",
    "    torch.sin(train_x[:, 0])\n",
    "    + torch.cos(train_x[:, 1]) * (2 * math.pi)\n",
    "    + torch.randn_like(train_x[:, 0]).mul(0.01)\n",
    ") / 4\n",
    "train_y_2 = (\n",
    "    torch.sin(train_x[:, 0])\n",
    "    + torch.cos(train_x[:, 1]) * (2 * math.pi)\n",
    "    + torch.randn_like(train_x[:, 0]).mul(0.01)\n",
    ")\n",
    "\n",
    "train_y = torch.stack([train_y_1, train_y_2], -1)\n",
    "\n",
    "test_x = torch.rand((n, len(train_x.shape)))\n",
    "test_y_1 = (\n",
    "    torch.sin(test_x[:, 0])\n",
    "    + torch.cos(test_x[:, 1]) * (2 * math.pi)\n",
    "    + torch.randn_like(test_x[:, 0]).mul(0.01)\n",
    ") / 4\n",
    "test_y_2 = (\n",
    "    torch.sin(test_x[:, 0])\n",
    "    + torch.cos(test_x[:, 1]) * (2 * math.pi)\n",
    "    + torch.randn_like(test_x[:, 0]).mul(0.01)\n",
    ")\n",
    "test_y = torch.stack([test_y_1, test_y_2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.unsqueeze(0).repeat(2, 1, 1)\n",
    "train_y = train_y.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 400])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument other in method wrapper_CUDA__equal)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/alujan/GitHub/alanlujan91/multinterp/src/multinterp/SKLearn.vs.GPyTorch.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/alujan/GitHub/alanlujan91/multinterp/src/multinterp/SKLearn.vs.GPyTorch.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iter):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/alujan/GitHub/alanlujan91/multinterp/src/multinterp/SKLearn.vs.GPyTorch.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/alujan/GitHub/alanlujan91/multinterp/src/multinterp/SKLearn.vs.GPyTorch.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     output \u001b[39m=\u001b[39m model(train_x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/alujan/GitHub/alanlujan91/multinterp/src/multinterp/SKLearn.vs.GPyTorch.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmll(output, train_y)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/alujan/GitHub/alanlujan91/multinterp/src/multinterp/SKLearn.vs.GPyTorch.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/multinterp-dev/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:264\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    260\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrain_inputs, train_targets cannot be None in training mode. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCall .eval() for prior predictions, or call .set_train_data() to add training data.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m     )\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m settings\u001b[39m.\u001b[39mdebug\u001b[39m.\u001b[39mon():\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39;49m(\n\u001b[1;32m    265\u001b[0m         torch\u001b[39m.\u001b[39;49mequal(train_input, \u001b[39minput\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m train_input, \u001b[39minput\u001b[39;49m \u001b[39min\u001b[39;49;00m length_safe_zip(train_inputs, inputs)\n\u001b[1;32m    266\u001b[0m     ):\n\u001b[1;32m    267\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must train on the training inputs!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    268\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/multinterp-dev/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:265\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    260\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrain_inputs, train_targets cannot be None in training mode. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCall .eval() for prior predictions, or call .set_train_data() to add training data.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m     )\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m settings\u001b[39m.\u001b[39mdebug\u001b[39m.\u001b[39mon():\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m--> 265\u001b[0m         torch\u001b[39m.\u001b[39;49mequal(train_input, \u001b[39minput\u001b[39;49m) \u001b[39mfor\u001b[39;00m train_input, \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m length_safe_zip(train_inputs, inputs)\n\u001b[1;32m    266\u001b[0m     ):\n\u001b[1;32m    267\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must train on the training inputs!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    268\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument other in method wrapper_CUDA__equal)"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)  # For a more robust comparison\n",
    "\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.MaternKernel(nu=2.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(num_tasks=2)\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "model.cuda()\n",
    "likelihood.cuda()\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\"params\": model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "    ],\n",
    "    lr=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "n_iter = 50\n",
    "for i in range(n_iter):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y).sum()\n",
    "    loss.backward()\n",
    "    print(\"Iter %d/%d - Loss: %.3f\" % (i + 1, n_iter, loss.item()))\n",
    "    optimizer.step()\n",
    "\n",
    "# Set into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    predictions = likelihood(model(test_x))\n",
    "    mean = predictions.mean\n",
    "    lower, upper = predictions.confidence_region()\n",
    "\n",
    "test_results_gpytorch = np.median(\n",
    "    (test_y.transpose(-2, -1) - mean) / test_y.transpose(-2, -1), axis=1\n",
    ")\n",
    "print(test_results_gpytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alujan/mambaforge-pypy3/envs/multinterp-dev/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, Matern\n",
    "\n",
    "kernel = (\n",
    "    1.0 * Matern(length_scale=0.1, length_scale_bounds=(1e-5, 1e5), nu=2.5)\n",
    "    + WhiteKernel()\n",
    ")\n",
    "gp = GaussianProcessRegressor(kernel=kernel, alpha=0.0).fit(\n",
    "    train_x[0].numpy(), train_y.transpose(-2, -1).numpy()\n",
    ")\n",
    "# x_interpolation = test_x.detach().numpy()[np.newaxis, :].transpose()\n",
    "y_mean_interpol, y_std_norm = gp.predict(test_x.numpy(), return_std=True)\n",
    "\n",
    "test_results_scitlearn = np.median((test_y.numpy() - y_mean_interpol), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable 1: scitkit learn is more accurate my factor: 7.576246355781184\n",
      "Variable 2: scitkit learn is more accurate my factor: 1.04243016558855\n"
     ]
    }
   ],
   "source": [
    "comparisson = (test_results_scitlearn - test_results_gpytorch) / test_results_scitlearn\n",
    "print(\n",
    "    \"Variable 1: scitkit learn is more accurate my factor: \" + str(abs(comparisson[0]))\n",
    ")\n",
    "print(\"Variable 2: scitkit learn is more accurate my factor: \" + str(comparisson[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.95036322e-05 -2.05220096e-03]\n"
     ]
    }
   ],
   "source": [
    "print(test_results_scitlearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
